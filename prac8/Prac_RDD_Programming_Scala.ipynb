{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prac 8 RDD Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RDD Creation\n",
    "There are two different ways to create RDDs. Please use given a document and collections to create RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "The University of Queensland (UQ) is a public research university located primarily in Brisbane, the capital city of the Australian state of Queensland. Founded in 1909 by the state parliament, UQ is one of the six sandstone universities, an informal designation of the oldest university in each state. The University of Queensland is ranked second nationally by Excellence in Research for Australia and equal second in Australia based on the average of four major global university league tables. The University of Queensland is a founding member of edX, Australia's research-intensive Group of Eight, the international research network McDonnell International Scholars Academy, and the global Universitas 21 network.\n",
      "\n",
      "The main St Lucia campus occupies much of the riverside inner suburb of St Lucia, southwest of the Brisbane central business district. Other UQ campuses and facilities are located throughout Queensland, the largest of which are the Gatton campus and the Mayne Medical School. UQ's overseas establishments include UQ North America office in Washington D.C., and the UQ-Ochsner Clinical School in Louisiana, United States.\n",
      "\n",
      "The university offers associate, bachelor, master, doctoral, and higher doctorate degrees through a college, a graduate school, and six faculties. UQ incorporates over one hundred research institutes and centres, such as the Institute for Molecular Bioscience, Boeing Research and Technology Australia Centre, the Australian Institute for Bioengineering and Nanotechnology, and the UQ Dow Centre for Sustainable Engineering Innovation. Recent research achievements of the university include pioneering the invention of the HPV vaccine that prevents cervical cancer, developing a COVID-19 vaccine currently in human trials and the development of high-performance superconducting MRI magnets for portable scanning of human limbs.\n",
      "\n",
      "UQ counts two Nobel laureates (Peter C. Doherty and John Harsanyi), over a hundred Olympians winning numerous gold medals and 117 Rhodes Scholars among its alumni and staff. UQ's alumni also include the President of the University of California San Francisco Sam Hawgood, the first female Governor-General of Australia Dame Quentin Bryce, President of King's College London Ed Byrne, member of United Kingdom's Prime Minister Council for Science and Technology Max Lu, Oscar and Emmy awards winner Geoffrey Rush, triple Grammy Award winner Tim Munro, former Chief Justices of Australia, and the former CEO and Chairman of Dow Chemical and current Director of DowDuPont Andrew N. Liveris. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "uqtext: org.apache.spark.rdd.RDD[String] = file:///home/jovyan/work/nbs/uq.txt MapPartitionsRDD[9] at textFile at <console>:34\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/* \n",
    "    Given text document is save at /home/jovyan/work/nba/uq.txt, please use textFile method to create an RDD \n",
    "*/\n",
    "//Input your code here:\n",
    "\n",
    "println(\"-------------\")\n",
    "\n",
    "val uqtext = sc.textFile(\"file:///home/jovyan/work/nbs/uq.txt\") \n",
    "\n",
    "uqtext.collect().foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "-------------\n",
      "MapReduce is good\n",
      "Spark is fast\n",
      "Spark is better than MapReduce\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dataArray: Array[Int] = Array(1, 2, 3, 4, 5)\n",
       "rddA: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[10] at parallelize at <console>:36\n",
       "dataList: List[String] = List(MapReduce is good, Spark is fast, Spark is better than MapReduce)\n",
       "rddS: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[11] at parallelize at <console>:39\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/*\n",
    "    Given two collections below:\n",
    "    I. 1, 2, 3, 4, 5\n",
    "    II. \"MapReduce is good\",\"Spark is fast\",\"Spark is better than MapReduce\"\n",
    "    please use parallelize method to create two RDDs\n",
    "*/\n",
    "//Input your code here: \n",
    "\n",
    "println(\"-------------\")\n",
    "\n",
    "val dataArray = Array(1, 2, 3, 4, 5)\n",
    "val rddA = sc.parallelize(dataArray)\n",
    "\n",
    "val dataList = List(\"MapReduce is good\",\"Spark is fast\",\"Spark is better than MapReduce\")\n",
    "val rddS = sc.parallelize(dataList)\n",
    "\n",
    "rddA.collect().foreach(println)\n",
    "println(\"-------------\")    \n",
    "rddS.collect().foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.RDD Transformations and Actions:\n",
    "In Spark, Transformations are functions that produces new RDD from an existing RDD. When you need actual data from a RDD, you need to apply actions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I@795e012b"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count: Array[Int] = Array(107, 1, 64, 1, 98, 1, 107)\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Transfermation\n",
    "//Split the uq.txt document into individual words, and get the word count of the document.\n",
    "//Input your code here:\n",
    "\n",
    "val count = uqtext.map(x => x.split(\" \").size).collect().sum\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348801626\n",
      "1690124788\n",
      "1111427557\n",
      "1274162139\n",
      "166632575\n",
      "1373772845\n",
      "390728099\n",
      "902860583\n",
      "1857459213\n",
      "606357572\n",
      "1620619452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import util.Random.nextInt\n",
       "collection: Seq[Int] = List(-691129786, 348801616, -2098481964, 1690124778, 1111427547, 1274162129, 166632565, 1373772835, 390728089, -1401923455, 902860573, -398510110, 1857459203, -975571417, -1788243111, -753115356, 606357562, -490585857, 1620619442, -2056184812)\n",
       "rddRandom: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[19] at parallelize at <console>:36\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Firstly, add each element in a collection by 10; secondly, display the elements that are greater than 12.\n",
    "\n",
    "\n",
    "/*\n",
    "Code below is to generate a ramdom integer collection \n",
    "*/\n",
    "import util.Random.nextInt\n",
    "val collection = Seq.fill(20)(util.Random.nextInt)\n",
    "val rddRandom = sc.parallelize(collection)\n",
    "//Input your code here:\n",
    "\n",
    "rddRandom.map(x => x + 10).filter(x=> x > 12).collect().foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infs3208\n",
      "infs7208\n",
      "infs3202\n",
      "infs7202\n",
      "infs3208\n",
      "infs3204\n",
      "infs7204\n",
      "infs7208\n",
      "-------------\n",
      "infs3208\n",
      "infs7204\n",
      "infs3202\n",
      "infs3204\n",
      "infs7208\n",
      "infs7202\n",
      "-------------\n",
      "infs3208\n",
      "infs7208\n",
      "infs3208\n",
      "infs7208\n",
      "-------------\n",
      "infs3202\n",
      "infs7202\n",
      "-------------\n",
      "(infs3202,infs3208)\n",
      "(infs3202,infs3208)\n",
      "(infs3202,infs3204)\n",
      "(infs3202,infs7204)\n",
      "(infs3202,infs7208)\n",
      "(infs7208,infs3208)\n",
      "(infs7208,infs3208)\n",
      "(infs7208,infs3204)\n",
      "(infs7208,infs7204)\n",
      "(infs7208,infs7208)\n",
      "(infs3208,infs3208)\n",
      "(infs3208,infs3208)\n",
      "(infs3208,infs3204)\n",
      "(infs3208,infs7204)\n",
      "(infs3208,infs7208)\n",
      "(infs7202,infs3208)\n",
      "(infs3208,infs3208)\n",
      "(infs7202,infs3208)\n",
      "(infs3208,infs3208)\n",
      "(infs7202,infs3204)\n",
      "(infs3208,infs3204)\n",
      "(infs7202,infs7204)\n",
      "(infs7202,infs7208)\n",
      "(infs3208,infs7204)\n",
      "(infs3208,infs7208)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rddSet1: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[33] at parallelize at <console>:40\n",
       "rddSet2: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[34] at parallelize at <console>:41\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/*\n",
    "    Given two different sets:\n",
    "    s1 = (\"infs3202\", \"infs7208\", \"infs3208\", \"infs7202\", \"infs3208\")\n",
    "    s2 = (\"infs3208\", \"infs3208\", \"infs3204\", \"infs7204\", \"infs7208\")\n",
    "*/\n",
    "\n",
    "// Create two RDDs using parallelize method\n",
    "\n",
    "// Display all distinct elements in the first RDD.\n",
    "// Input your code here:\n",
    "val rddSet1 = sc.parallelize(List(\"infs3202\", \"infs7208\", \"infs3208\", \"infs7202\", \"infs3208\"))\n",
    "val rddSet2 = sc.parallelize(List(\"infs3208\", \"infs3208\", \"infs3204\", \"infs7204\", \"infs7208\"))\n",
    "rddSet1.distinct().collect().foreach(println)\n",
    "rddSet2.distinct().collect().foreach(println)\n",
    "\n",
    "// Display all distinct elements in all the RDDs.\n",
    "// In put your code here:\n",
    "println(\"-------------\")\n",
    "rddSet1.union(rddSet2).distinct().collect().foreach(println)\n",
    "\n",
    "// Display all common elements between two RDDs.\n",
    "// In put your code here:\n",
    "println(\"-------------\")\n",
    "rddSet1.intersection(rddSet2).collect().foreach(println)\n",
    "rddSet2.intersection(rddSet1).collect().foreach(println)\n",
    "\n",
    "// Subtract the first RDD with the second RDD and display the result.\n",
    "// In put your code here:\n",
    "println(\"-------------\")\n",
    "rddSet1.subtract(rddSet2).collect().foreach(println)\n",
    "\n",
    "\n",
    "// Display all the cartesian products between the first RDD and the second RDD:\n",
    "// In put your code here:\n",
    "println(\"-------------\")\n",
    "rddSet1.cartesian(rddSet2).collect().foreach(println)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List(-2049694065, -1465116994, 884062310, 887416240, -1157174696, 442150354, -2144180902, 2106782380, -1878610681, -824181523, -896202930, 679335574, -373348744, 413898436, 1069952338, -21148358, 220798601, 46464531, -718929032, 1060296775)\n",
      "637534208\n",
      "-------------\n",
      "577536910\n",
      "-------------\n",
      "20\n",
      "-------------\n",
      "887416240\n",
      "-1157174696\n",
      "-2049694065\n",
      "679335574\n",
      "-------------\n",
      "2106782380\n",
      "1069952338\n",
      "-------------\n",
      "(1060296775,1)\n",
      "(413898436,1)\n",
      "(887416240,1)\n",
      "(-1878610681,1)\n",
      "(884062310,1)\n",
      "(679335574,1)\n",
      "(1069952338,1)\n",
      "(-2049694065,1)\n",
      "(-896202930,1)\n",
      "(-21148358,1)\n",
      "(2106782380,1)\n",
      "(220798601,1)\n",
      "(-1157174696,1)\n",
      "(442150354,1)\n",
      "(-718929032,1)\n",
      "(-1465116994,1)\n",
      "(-824181523,1)\n",
      "(-373348744,1)\n",
      "(46464531,1)\n",
      "(-2144180902,1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import util.Random.nextInt\n",
       "collection: Seq[Int] = List(-2049694065, -1465116994, 884062310, 887416240, -1157174696, 442150354, -2144180902, 2106782380, -1878610681, -824181523, -896202930, 679335574, -373348744, 413898436, 1069952338, -21148358, 220798601, 46464531, -718929032, 1060296775)\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Action operations\n",
    "/*\n",
    "Given below code to generate a ramdom collection: \n",
    "import util.Random.nextInt\n",
    "val collection = Seq.fill(20)(util.Random.nextInt)\n",
    "*/\n",
    "import util.Random.nextInt\n",
    "val collection = Seq.fill(20)(util.Random.nextInt)\n",
    "\n",
    "// Get the product of sequence of the RDD\n",
    "// Input your code here:\n",
    "println(collection)\n",
    "println(sc.parallelize(collection).reduce(_*_))\n",
    "\n",
    "\n",
    "// Produce the sum of the RDD \n",
    "// Input your code here:\n",
    "println(\"-------------\")\n",
    "println(sc.parallelize(collection).reduce(_+_ ))\n",
    "\n",
    "\n",
    "// Count the elements in the RDD\n",
    "// Input your code here:\n",
    "println(\"-------------\")\n",
    "println(sc.parallelize(collection).count)\n",
    "\n",
    "\n",
    "// Ramdomly select 4 elements out of the RDD, and print them out.\n",
    "// Input your code here:\n",
    "println(\"-------------\")\n",
    "sc.parallelize(collection).takeSample(false,4).foreach(println)\n",
    "\n",
    "\n",
    "// Display the two largest elements in the RDD\n",
    "// Input your code here:\n",
    "println(\"-------------\")\n",
    "sc.parallelize(collection).top(2).foreach(println)\n",
    "\n",
    "\n",
    "// Check the frequency of each element in the RDD\n",
    "// Input your code here:\n",
    "println(\"-------------\")\n",
    "sc.parallelize(collection).countByValue().foreach(println)\n",
    "//rddSample1.collect.foreach(println)\n",
    "//println(rddSample1.partitions.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "collection = List(-1464005908, -318129081, -270866310, 1938995203, 1625880626, 1150292814, -1714962957, 265845331, 879749033, -673752055, 2116125027, 76783263, -198906893, -1649957629, 139370082, 1547636385, -1397515656, 93558156, 2092365610, 681442474)\n",
       "rddSampleRePar = MapPartitionsRDD[79] at repartition at <console>:39\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[79] at repartition at <console>:39"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Partition & repartition\n",
    "\n",
    "/*\n",
    "Given below code to generate a ramdom collection: \n",
    "import util.Random.nextInt\n",
    "val collection = Seq.fill(20)(util.Random.nextInt)\n",
    "*/\n",
    "import util.Random.nextInt\n",
    "val collection = Seq.fill(20)(util.Random.nextInt)\n",
    "\n",
    "//Generate a partition of the collection\n",
    "//Input your code here:\n",
    "val rddSampleRePar = sc.parallelize(collection).repartition(2)\n",
    "\n",
    "println(sc.parallelize(collection).partitions.size)\n",
    "println(rddSampleRePar.partitions.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Key/Value Pair Creation and Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(MapReduce,1)\n",
      "(is,1)\n",
      "(good,1)\n",
      "(Spark,1)\n",
      "(is,1)\n",
      "(fast,1)\n",
      "(Spark,1)\n",
      "(is,1)\n",
      "(better,1)\n",
      "(than,1)\n",
      "(MapReduce,1)\n",
      "-------------\n",
      "(better,1)\n",
      "(than,1)\n",
      "(Spark,2)\n",
      "(is,3)\n",
      "(fast,1)\n",
      "(MapReduce,2)\n",
      "(good,1)\n",
      "-------------\n",
      "(the,69)\n",
      "(of,33)\n",
      "(and,22)\n",
      "(university,13)\n",
      "(in,13)\n",
      "(to,11)\n",
      "(a,9)\n",
      "(arms,8)\n",
      "(queensland,7)\n",
      "(on,7)\n",
      "(for,6)\n",
      "(was,6)\n",
      "(university’s,5)\n",
      "(coat,5)\n",
      "(seal,5)\n",
      "(college,5)\n",
      "(its,4)\n",
      "(as,4)\n",
      "(senate,4)\n",
      "(motto,4)\n",
      "(by,4)\n",
      "(that,4)\n",
      "(however,,3)\n",
      "(with,3)\n",
      "(an,3)\n",
      "(debate,3)\n",
      "(about,3)\n",
      "(at,3)\n",
      "(ac,2)\n",
      "(have,2)\n",
      "(first,2)\n",
      "(are,2)\n",
      "(proposed,2)\n",
      "(since,2)\n",
      "(june,2)\n",
      "(london,2)\n",
      "(scientia,2)\n",
      "(variations,2)\n",
      "(cross,2)\n",
      "(open,2)\n",
      "(universities,2)\n",
      "(considerable,2)\n",
      "(common,2)\n",
      "(suggests,2)\n",
      "(corporate,2)\n",
      "(1912,2)\n",
      "(hand,2)\n",
      "(great,2)\n",
      "(book,2)\n",
      "(provided,2)\n",
      "(amongst,2)\n",
      "(both,2)\n",
      "(before,2)\n",
      "(seal’s,2)\n",
      "(seal,,2)\n",
      "(state,2)\n",
      "(press,2)\n",
      "(were,2)\n",
      "(device,1)\n",
      "(means,1)\n",
      "(contemporaneous,1)\n",
      "(general,1)\n",
      "(order,1)\n",
      "(still,1)\n",
      "(established,1)\n",
      "(knights,1)\n",
      "(been,1)\n",
      "(who,1)\n",
      "(located,1)\n",
      "(herald’s,1)\n",
      "(century,,1)\n",
      "(latin.,1)\n",
      "(magazine,1)\n",
      "(13,1)\n",
      "(late,1)\n",
      "(tradition,1)\n",
      "(version,1)\n",
      "(constructed,1)\n",
      "(orama.,1)\n",
      "(1911,1)\n",
      "(locks,1)\n",
      "(pragmatic,1)\n",
      "(universities,,1)\n",
      "(act,1)\n",
      "(ss,1)\n",
      "(students,,1)\n",
      "(can,1)\n",
      "(secretary,1)\n",
      "((later,1)\n",
      "(queensland,,1)\n",
      "(senate’s,1)\n",
      "(featured,1)\n",
      "(them.,1)\n",
      "(into,1)\n",
      "(reflected,1)\n",
      "(numerous,1)\n",
      "(arms),1)\n",
      "(flag,,1)\n",
      "(inscription,1)\n",
      "(design,1)\n",
      "(form,1)\n",
      "(lucia,1)\n",
      "(survived,,1)\n",
      "(1912.the,1)\n",
      "(final,1)\n",
      "(latin,1)\n",
      "(today.the,1)\n",
      "(seals,1)\n",
      "(selection,1)\n",
      "(patent,1)\n",
      "(appearance,1)\n",
      "(program.,1)\n",
      "(is,1)\n",
      "(correspondence,1)\n",
      "(same,1)\n",
      "(associated,1)\n",
      "(unknown,,1)\n",
      "(adoption,1)\n",
      "(staff,1)\n",
      "(1991,1)\n",
      "(institution’s,1)\n",
      "(followed,1)\n",
      "(subject,1)\n",
      "(building,1)\n",
      "(from,1)\n",
      "(has,1)\n",
      "(purpose.,1)\n",
      "(body,1)\n",
      "(after,1)\n",
      "(two,1)\n",
      "(work),,1)\n",
      "(remain,1)\n",
      "(april,1)\n",
      "(down,1)\n",
      "(example,,1)\n",
      "(places,1)\n",
      "(report,1)\n",
      "(testamurs,,1)\n",
      "(identity,1)\n",
      "(administrative,1)\n",
      "(herald,1)\n",
      "(knowledge,1)\n",
      "(documents,1)\n",
      "(kidston,1)\n",
      "(colonies.,1)\n",
      "(1911.,1)\n",
      "(premier,1)\n",
      "(being,1)\n",
      "(agent,1)\n",
      "(“queensland”,1)\n",
      "((by,1)\n",
      "(it,1)\n",
      "(content,1)\n",
      "(having,1)\n",
      "(received,1)\n",
      "(annual,1)\n",
      "(mirror,1)\n",
      "(commenced,1)\n",
      "(chancellor,,1)\n",
      "(through,1)\n",
      "(march,1)\n",
      "(painter,1)\n",
      "(formed,1)\n",
      "(seen,1)\n",
      "(which,1)\n",
      "(foyer,1)\n",
      "(following,1)\n",
      "(should,1)\n",
      "(birth,1)\n",
      "(rules,1)\n",
      "(used,1)\n",
      "(frameworks.,1)\n",
      "(time,1)\n",
      "(universitas,,1)\n",
      "(labore.,1)\n",
      "(placed,1)\n",
      "(1912.,1)\n",
      "(smith,1)\n",
      "(granted.,1)\n",
      "(arrived,1)\n",
      "(scholars,1)\n",
      "(steamer,1)\n",
      "(different,1)\n",
      "(not,1)\n",
      "(hard,1)\n",
      "(put,1)\n",
      "(internal,1)\n",
      "(bears,1)\n",
      "(27,1)\n",
      "(be,1)\n",
      "(source,1)\n",
      "(carved,1)\n",
      "(affixed,1)\n",
      "(letters,1)\n",
      "(including,1)\n",
      "(campus.,1)\n",
      "(authenticate,1)\n",
      "(legend,1)\n",
      "(terrae,1)\n",
      "(closely,1)\n",
      "(suggestions,1)\n",
      "(shield,1)\n",
      "(size,1)\n",
      "(manufactured,1)\n",
      "(badge,1)\n",
      "(memorandum,1)\n",
      "(delegation.the,1)\n",
      "(fifteenth,1)\n",
      "(establishing,1)\n",
      "(custody,1)\n",
      "(public.,1)\n",
      "(least,1)\n",
      "(william,1)\n",
      "(had,1)\n",
      "(mid-1911,,1)\n",
      "(number,1)\n",
      "(known,1)\n",
      "(inauguration.by,1)\n",
      "(agreements.,1)\n",
      "(origins,1)\n",
      "(while,1)\n",
      "(seal.,1)\n",
      "(16,1)\n",
      "(state’s,1)\n",
      "(britain.,1)\n",
      "(st,1)\n",
      "(1934,1)\n",
      "(columns,1)\n",
      "(expressed,1)\n",
      "(progressive,1)\n",
      "(discussions,1)\n",
      "(macgregor,,1)\n",
      "(garter,1)\n",
      "(1912.this,1)\n",
      "(deeds,,1)\n",
      "(use,1)\n",
      "(academic,1)\n",
      "(submitted,1)\n",
      "(reginae,1)\n",
      "(approved,1)\n",
      "(motto,,1)\n",
      "(1910,,1)\n",
      "(granted,1)\n",
      "(forward,1)\n",
      "(name,1)\n",
      "(forgan,1)\n",
      "(proposals,1)\n",
      "(1909,1)\n",
      "(contracts,1)\n",
      "(request,1)\n",
      "(identical,1)\n",
      "(translation,1)\n",
      "(1910.,1)\n",
      "(newly,1)\n",
      "(chancellor,1)\n",
      "(designer,1)\n",
      "(months,1)\n",
      "(subsequent,1)\n",
      "(occurred,1)\n",
      "(ethos,1)\n",
      "(labore,1)\n",
      "(approval,1)\n",
      "(examined,1)\n",
      "(–,1)\n",
      "(lays,1)\n",
      "(reasons,1)\n",
      "(artist,1)\n",
      "(became,1)\n",
      "(s123456,78)\n",
      "(s123456,80)\n",
      "(s123456,65)\n",
      "(s123456,90)\n",
      "(s654321,80)\n",
      "(s654321,40)\n",
      "(s654321,50)\n",
      "(s654321,90)\n",
      "(s654321,80)\n",
      "-------------\n",
      "(s654321,68)\n",
      "(s123456,78)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rddS = ParallelCollectionRDD[81] at parallelize at <console>:47\n",
       "rddPairS = MapPartitionsRDD[83] at map at <console>:48\n",
       "lines = file:///root/infs3208/code/uq.txt MapPartitionsRDD[86] at textFile at <console>:61\n",
       "rddWC1 = MapPartitionsRDD[88] at map at <console>:62\n",
       "rddWC2 = MapPartitionsRDD[89] at map at <console>:63\n",
       "rddCount = ShuffledRDD[90] at reduceByKey at <console>:64\n",
       "rddStudent = ParallelCollectionRDD[96] at parallelize at <console>:78\n",
       "rddScores = ParallelCollectionRDD[97] at parallelize at <consol...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[97] at parallelize at <consol..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/*\n",
    "Given a List of String:\n",
    "    \"MapReduce is good\",\"Spark is fast\",\"Spark is better than MapReduce\"\n",
    " \n",
    " create an RDD and count the word frequency using transformation operations, followed by displaying the results using \n",
    " action operations. \n",
    " */\n",
    "//Input your code here:\n",
    "\n",
    "val rddS = sc.parallelize(List(\"MapReduce is good\",\"Spark is fast\",\"Spark is better than MapReduce\"))\n",
    "val rddPairS = rddS.flatMap(x => x.split(\" \")).map(x => (x,1))\n",
    "rddPairS.collect.foreach(println)\n",
    "println(\"-------------\")\n",
    "rddPairS.reduceByKey((a,b) => (a+b)).collect.foreach(println)\n",
    "println(\"-------------\")\n",
    "\n",
    "\n",
    "/* \n",
    "    Given a text document that is save at /root/infs3208/code/uq.txt, convert all words into lower case and\n",
    "    count the word frquency, followed by displaying the sorted results (descending order of frequency) using action operations.    \n",
    "*/ \n",
    "\n",
    "//Input your coder here:\n",
    "val lines = sc.textFile(\"file:///home/jovyan/work/nbs/uq.txt\") \n",
    "val rddWC1 = lines.flatMap(line => line.split(\" \")).map(x=>x.toLowerCase())\n",
    "val rddWC2 = rddWC1.map(word => (word, 1))\n",
    "val rddCount = rddWC2.reduceByKey((a, b) => (a+b))\n",
    "\n",
    "rddCount.sortBy(_._2,false).collect.foreach(println)\n",
    "\n",
    "\n",
    "/*\n",
    " Given scores of two students below:\n",
    "    \"s123456\",78\n",
    "    \"s123456\",80\n",
    "    \"s123456\",65\n",
    "    \"s123456\",90\n",
    "    \"s654321\",80\n",
    "    \"s654321\",40\n",
    "    \"s654321\",50\n",
    "    \"s654321\",90 \n",
    "    \"s654321\" 80 \n",
    " \n",
    " store the data into an RDD and calculate the average scores for each student.\n",
    " */\n",
    "//Input your code here:\n",
    "\n",
    "val rddStudent = sc.parallelize(List(\"s123456\",\"s123456\",\"s123456\", \"s123456\", \"s654321\", \"s654321\", \"s654321\", \"s654321\", \"s654321\"))\n",
    "val rddScores = sc.parallelize(Array(78,80,65,90,80,40,50,90,80))\n",
    "val rddPairScores = rddStudent.zip(rddScores)\n",
    "rddPairScores.collect.foreach(println)\n",
    "\n",
    "println(\"-------------\")\n",
    "\n",
    "rddPairScores.mapValues(x => (x,1)).reduceByKey((x,y) => (x._1+y._1, x._2+y._2)).mapValues(x => x._1/x._2).collect.foreach(println)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}